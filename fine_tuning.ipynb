{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Classificador: XGBClassifier\n",
      "Melhores parâmetros: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Melhor pontuação: 0.910483870967742\n",
      "Acurácia no conjunto de teste: 0.8974358974358975\n",
      "\n",
      "  O melhor estimator foi: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=50, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\napós diversos testes, \\né possível concluir que:\\nGradientBoostingClassifier(learning_rate=0.1, n_estimators=50)\\nfoi o que obteve maior pontuação e acurácia nos testes.\\n '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Carregar base de dados\n",
    "diretorio_atual = os.getcwd()\n",
    "\n",
    "caminho_dataset = os.path.join(diretorio_atual, 'datasets', 'parkinsons.data')\n",
    "\n",
    "df = pd.read_csv(caminho_dataset)\n",
    "\n",
    "X = df.drop(['status', 'name', 'APQ', 'D2',\n",
    "            'Fhi(Hz)', 'Flo(Hz)', 'Fo(Hz)',\n",
    "             'PPQ', 'RAP', 'spread1', 'spread2'], axis=1)\n",
    "\n",
    "y = df['status']\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Definir os classificadores e os seus parâmetros obs: poderia também ser usado uma Pipeline\n",
    "classificadores = [XGBClassifier()]\n",
    "parametros = [# Parâmetros para GradientBoostingClassifier\n",
    "    {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.5], 'max_depth': [2, 3, 4, 5]},\n",
    "]\n",
    "# Listas para armazenar os melhores resultados para cada classificador\n",
    "melhores_parametros = []\n",
    "melhor_pontuacao = []\n",
    "teste_precisao = []\n",
    "\n",
    "# Loop sobre os classificadores\n",
    "for classificador, parametro in zip(classificadores, parametros):\n",
    "    # Criar o objeto GridSearchCV\n",
    "    grid_search = GridSearchCV(classificador, parametro, cv=5)\n",
    "\n",
    "    # Ajustar o objeto GridSearchCV aos dados de treinamento\n",
    "    grid_search.fit(X_treino, y_treino)\n",
    "\n",
    "    # Melhores parâmetros encontrados\n",
    "    melhores_parametros.append(grid_search.best_params_)\n",
    "\n",
    "    # Melhor pontuação no conjunto de validação cruzada\n",
    "    melhor_pontuacao.append(grid_search.best_score_)\n",
    "\n",
    "    # Avaliar o desempenho no conjunto de teste\n",
    "    teste_precisao.append(grid_search.score(X_teste, y_teste))\n",
    "\n",
    "\n",
    "# Imprimir resultados para cada classificador\n",
    "for i, classificador in enumerate(classificadores):\n",
    "    print(f\"\\n  Classificador: {classificador.__class__.__name__}\")\n",
    "    print(f\"Melhores parâmetros: {melhores_parametros[i]}\")\n",
    "    print(f\"Melhor pontuação: {melhor_pontuacao[i]}\")\n",
    "    print(f\"Acurácia no conjunto de teste: {teste_precisao[i]}\")\n",
    "\n",
    "print(f\"\\n  O melhor estimator foi: {grid_search.best_estimator_}\")\n",
    "\n",
    "\n",
    "'''\n",
    "após diversos testes, \n",
    "é possível concluir que:\n",
    "GradientBoostingClassifier(learning_rate=0.1, n_estimators=50)\n",
    "foi o que obteve maior pontuação e acurácia nos testes.\n",
    " '''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
