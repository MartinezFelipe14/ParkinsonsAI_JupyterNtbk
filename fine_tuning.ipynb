{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Carregar base de dados\n",
    "df = pd.read_csv('parkinsons.data')\n",
    "\n",
    "X = df.drop(['status', 'name', 'APQ', 'D2',\n",
    "            'Fhi(Hz)', 'Flo(Hz)', 'Fo(Hz)',\n",
    "             'PPQ', 'RAP', 'spread1', 'spread2'], axis=1)\n",
    "\n",
    "y = df['status']\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Definir os classificadores e os seus parâmetros obs: poderia também ser usado uma Pipeline\n",
    "classificadores = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()]\n",
    "parametros = [\n",
    "    # Parâmetros para DecisionTreeClassifier\n",
    "    {'max_depth': [None, 5, 10, 20, 50]},\n",
    "    # Parâmetros para RandomForestClassifier\n",
    "    {'n_estimators': [50, 100, 200]},\n",
    "    # Parâmetros para GradientBoostingClassifier\n",
    "    {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.5]}\n",
    "]\n",
    "# Listas para armazenar os melhores resultados para cada classificador\n",
    "melhores_parametros = []\n",
    "melhor_pontuacao = []\n",
    "teste_precisao = []\n",
    "\n",
    "# Loop sobre os classificadores\n",
    "for classificador, parametro in zip(classificadores, parametros):\n",
    "    # Criar o objeto GridSearchCV\n",
    "    grid_search = GridSearchCV(classificador, parametro, cv=5)\n",
    "\n",
    "    # Ajustar o objeto GridSearchCV aos dados de treinamento\n",
    "    grid_search.fit(X_treino, y_treino)\n",
    "\n",
    "    # Melhores parâmetros encontrados\n",
    "    melhores_parametros.append(grid_search.best_params_)\n",
    "\n",
    "    # Melhor pontuação no conjunto de validação cruzada\n",
    "    melhor_pontuacao.append(grid_search.best_score_)\n",
    "\n",
    "    # Avaliar o desempenho no conjunto de teste\n",
    "    teste_precisao.append(grid_search.score(X_teste, y_teste))\n",
    "\n",
    "\n",
    "# Imprimir resultados para cada classificador\n",
    "for i, classificador in enumerate(classificadores):\n",
    "    print(f\"\\n  Classificador: {classificador.__class__.__name__}\")\n",
    "    print(f\"Melhores parâmetros: {melhores_parametros[i]}\")\n",
    "    print(f\"Melhor pontuação: {melhor_pontuacao[i]}\")\n",
    "    print(f\"Acurácia no conjunto de teste: {teste_precisao[i]}\")\n",
    "\n",
    "print(f\"\\n  O melhor estimator foi: {grid_search.best_estimator_}\")\n",
    "\n",
    "\n",
    "'''\n",
    "após diversos testes, \n",
    "é possível concluir que:\n",
    "GradientBoostingClassifier(learning_rate=0.1, n_estimators=50)\n",
    "foi o que obteve maior pontuação e acurácia nos testes.\n",
    " '''\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
